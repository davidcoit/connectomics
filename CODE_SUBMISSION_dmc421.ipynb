{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import numpy as np\n",
    "import random\n",
    "import scipy.signal as sgn\n",
    "import scipy.misc\n",
    "import scipy.stats as stats\n",
    "import pandas as pd\n",
    "import os\n",
    "import shutil\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import gc\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc, average_precision_score \n",
    "import seaborn as sns\n",
    "import sys\n",
    "\n",
    "\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, IterableDataset, DataLoader, RandomSampler, ConcatDataset\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import WeightedRandomSampler\n",
    "\n",
    "if torch.cuda.is_available:\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# create connection (adjacency) matrix from network files\n",
    "def connectionMatrix(fmat, nlist):\n",
    "    n = np.shape(fmat)[1]\n",
    "    cmat = np.zeros((n,n))\n",
    "    for connection in nlist:\n",
    "        nfrom = connection[0] - 1 # subtract 1 for python indexing\n",
    "        nto = connection[1] - 1\n",
    "        if connection[2] == 1:\n",
    "            cmat[nfrom, nto] = 1\n",
    "            cmat[nto, nfrom] = 1\n",
    "    return(cmat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# define dataset number to dataset name dict for easy modular loading\n",
    "dataset_dict = {\n",
    "    1: 'normal-1',\n",
    "    2: 'normal-2',\n",
    "    3: 'normal-3',\n",
    "    4: 'normal-4',\n",
    "    5: 'normal-3-highrate',\n",
    "    6: 'normal-4-lownoise',\n",
    "    7: 'lowcon',\n",
    "    8: 'highcon',\n",
    "    9: 'lowcc',\n",
    "    10: 'highcc',\n",
    "    11: 'small-1',\n",
    "    12: 'small-2',\n",
    "    13: 'small-3',\n",
    "    14: 'small-4',\n",
    "    15: 'small-5',\n",
    "    16: 'small-6'\n",
    "}\n",
    "\n",
    "# define paths to data\n",
    "data_parent_dir = \"/scratch/dmc421/dlproject/data\"\n",
    "\n",
    "# dataset name : path\n",
    "data_dir = {}\n",
    "for v in dataset_dict.values():\n",
    "    data_dir.update({v: str(os.path.join(data_parent_dir, v))})\n",
    "\n",
    "# dataset filename : path\n",
    "flr_dir = {}\n",
    "net_dir = {}\n",
    "pos_dir = {}\n",
    "\n",
    "denoised_dir = {}\n",
    "denoised_weighted_dir = {}\n",
    "\n",
    "spike_dir = {}\n",
    "spike_weighted_dir = {}\n",
    "binspike_dir = {}\n",
    "\n",
    "# update dictionaries with corresponding filepaths\n",
    "for dataset in data_dir.keys():\n",
    "    for f in os.listdir(data_dir[dataset]):\n",
    "        filepath = os.path.join(data_dir[dataset], f)\n",
    "        if \"networkPositions\" in f:\n",
    "            pos_dir.update({dataset: filepath})\n",
    "        elif \"network\" in f:\n",
    "            net_dir.update({dataset: filepath})\n",
    "        elif \"denoised_weighted\" in f:\n",
    "            denoised_weighted_dir.update({dataset:filepath})\n",
    "        elif \"denoised\" in f:\n",
    "            denoised_dir.update({dataset:filepath})\n",
    "        elif \"spike_weighted\" in f:\n",
    "            spike_weighted_dir.update({dataset:filepath})\n",
    "        elif \"binspike\" in f:\n",
    "            binspike_dir.update({dataset:filepath})\n",
    "        elif \"spike\" in f:\n",
    "            spike_dir.update({dataset:filepath})\n",
    "        elif \"fluorescence\" in f:\n",
    "            flr_dir.update({dataset: filepath})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# import network files and denoised flr files\n",
    "npath_1 = net_dir[dataset_dict[11]]\n",
    "npath_2 = net_dir[dataset_dict[12]]\n",
    "npath_3 = net_dir[dataset_dict[13]]\n",
    "npath_4 = net_dir[dataset_dict[14]]\n",
    "npath_5 = net_dir[dataset_dict[15]]\n",
    "npath_6 = net_dir[dataset_dict[16]]\n",
    "\n",
    "fpath_1 = denoised_dir[dataset_dict[11]]\n",
    "fpath_2 = denoised_dir[dataset_dict[12]]\n",
    "fpath_3 = denoised_dir[dataset_dict[13]]\n",
    "fpath_4 = denoised_dir[dataset_dict[14]]\n",
    "fpath_5 = denoised_dir[dataset_dict[15]]\n",
    "fpath_6 = denoised_dir[dataset_dict[16]]\n",
    "\n",
    "# import network mappings\n",
    "network_1 = np.genfromtxt(\n",
    "    npath_1,\n",
    "    delimiter=',').astype(int)\n",
    "network_2 = np.genfromtxt(\n",
    "    npath_2,\n",
    "    delimiter=',').astype(int)\n",
    "network_3 = np.genfromtxt(\n",
    "    npath_3,\n",
    "    delimiter=',').astype(int)\n",
    "network_4 = np.genfromtxt(\n",
    "    npath_4,\n",
    "    delimiter=',').astype(int)\n",
    "network_5 = np.genfromtxt(\n",
    "    npath_5,\n",
    "    delimiter=',').astype(int)\n",
    "network_6 = np.genfromtxt(\n",
    "    npath_6,\n",
    "    delimiter=',').astype(int)\n",
    "\n",
    "print(\"networks loaded\")\n",
    "\n",
    "# import fluorescence data\n",
    "flr_1 = np.genfromtxt(\n",
    "    fpath_1,\n",
    "    delimiter=',')\n",
    "flr_2 = np.genfromtxt(\n",
    "    fpath_2,\n",
    "    delimiter=',')\n",
    "flr_3 = np.genfromtxt(\n",
    "    fpath_3,\n",
    "    delimiter=',')\n",
    "flr_4 = np.genfromtxt(\n",
    "    fpath_4,\n",
    "    delimiter=',')\n",
    "flr_5 = np.genfromtxt(\n",
    "    fpath_5,\n",
    "    delimiter=',')\n",
    "flr_6 = np.genfromtxt(\n",
    "    fpath_6,\n",
    "    delimiter=',')\n",
    "\n",
    "print(\"flrs loaded\")\n",
    "\n",
    "# create connection (adjacency) matrices\n",
    "con_1 = connectionMatrix(flr_1, network_1)\n",
    "con_2 = connectionMatrix(flr_2, network_2)\n",
    "con_3 = connectionMatrix(flr_3, network_3)\n",
    "con_4 = connectionMatrix(flr_4, network_4)\n",
    "con_5 = connectionMatrix(flr_5, network_5)\n",
    "con_6 = connectionMatrix(flr_6, network_6)\n",
    "print(\"connection matrices constructed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# examine the number of positive examples per dataset\n",
    "print(np.sum(con_1))\n",
    "print(np.sum(con_2))\n",
    "print(np.sum(con_3))\n",
    "print(np.sum(con_4))\n",
    "print(np.sum(con_5))\n",
    "print(np.sum(con_6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# create a dataset in line with the filtering criteria from Romaszko / Dunn & Koo\n",
    "# adapted from https://github.com/spoonsso/TFconnect/blob/master/conutils/utils.py\n",
    "class RomaDataset(Dataset):\n",
    "    def __init__(self, flrmat, conmat, seq_len=330, th=0.02):\n",
    "        self.flrmat = flrmat\n",
    "        self.conmat = conmat\n",
    "        self.seq_len = seq_len\n",
    "        self.th = th\n",
    "        \n",
    "        self.n_neurons = np.shape(self.flrmat)[1]\n",
    "        self.n_pairs = np.shape(self.flrmat)[1]**2 #possible pairs including identical pairs\n",
    "        self.n_timesamples = np.shape(self.flrmat)[0]\n",
    "        self.sum_thresh = self.th * self.n_neurons\n",
    "               \n",
    "        # z-score input flr matrix\n",
    "        self.flrz = stats.zscore(flrmat, axis=1)\n",
    "        \n",
    "        self.avg = np.mean(self.flrmat, axis=1)\n",
    "        self.avgz = stats.zscore(self.avg)\n",
    "        \n",
    "        # take the diff matrix per Romaszko paper / spoonsso implementation\n",
    "        fdiff = np.diff(flrmat, axis=0)\n",
    "        totF = np.sum(fdiff, axis=1)\n",
    "        totF = np.hstack([totF, totF[-1]]) # repeat last value for boolean logic size match\n",
    "        self.ffilt = self.flrz[(totF>self.sum_thresh), :]\n",
    "        self.avg = self.avg[(totF>self.sum_thresh)]\n",
    "       \n",
    "        self.n_timesamples_filt = np.shape(self.ffilt)[0]\n",
    "        \n",
    "    # length of dataset is the number of pairs    \n",
    "    def __len__(self):\n",
    "        return self.n_pairs\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        self.p1 = int(np.floor(idx / self.n_neurons)) # from neuron     \n",
    "        self.p2 = int(idx % self.n_neurons) # to neuron\n",
    "        \n",
    "        # pick a random time window of filtered flr matrix\n",
    "        self.start = np.random.randint(0, self.n_timesamples_filt - self.seq_len - 1)\n",
    "        self.end = self.start + self.seq_len\n",
    "\n",
    "        \n",
    "        ##### BUILD TRACKS #######\n",
    "        # flr tracks\n",
    "        self.flr_from_track = self.ffilt[self.start:self.end, self.p1]\n",
    "        self.flr_to_track = self.ffilt[self.start:self.end, self.p2]\n",
    "        self.avg_track = self.avgz[self.start:self.end]\n",
    "                        \n",
    "        # Assemble a single 3x330 track for training / evaluation\n",
    "        self.track = torch.Tensor([\n",
    "            self.flr_from_track,\n",
    "            self.avg_track,\n",
    "            self.flr_to_track\n",
    "        ])\n",
    "        \n",
    "        \n",
    "        # produce label for generated track\n",
    "        self.contype = torch.Tensor([self.conmat[self.p1, self.p2]])\n",
    "        \n",
    "        # produce the time window used (for debugging purposes)\n",
    "        self.samples = torch.Tensor([self.start, self.end])\n",
    "            \n",
    "        return(self.track, self.contype, self.samples)\n",
    "\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# set the model sequence length and fluorescence threshold to generate datasets\n",
    "seq_len = 330\n",
    "th = 0.02\n",
    "\n",
    "dataset_1 = RomaDataset(\n",
    "    flr_1, \n",
    "    con_1,\n",
    "    seq_len=seq_len,\n",
    "    th=th)\n",
    "\n",
    "dataset_2 = RomaDataset(\n",
    "    flr_2, \n",
    "    con_2,\n",
    "    seq_len=seq_len,\n",
    "    th=th)\n",
    "\n",
    "dataset_3 = RomaDataset(\n",
    "    flr_3, \n",
    "    con_3,\n",
    "    seq_len=seq_len,\n",
    "    th=th)\n",
    "\n",
    "dataset_4 = RomaDataset(\n",
    "    flr_4, \n",
    "    con_4,\n",
    "    seq_len=seq_len,\n",
    "    th=th)\n",
    "\n",
    "dataset_5 = RomaDataset(\n",
    "    flr_5, \n",
    "    con_5,\n",
    "    seq_len=seq_len,\n",
    "    th=th)\n",
    "\n",
    "dataset_6 = RomaDataset(\n",
    "    flr_6, \n",
    "    con_6,\n",
    "    seq_len=seq_len,\n",
    "    th=th)\n",
    "\n",
    "\n",
    "# train on datasets 1:4, validate on 5, test on 6\n",
    "dataset_combined = ConcatDataset([dataset_1, dataset_2, dataset_3, dataset_4])\n",
    "dataset_validation = dataset_5\n",
    "\n",
    "transformed_dataset = {\n",
    "    'train': dataset_combined,\n",
    "    'validate': dataset_5\n",
    "}\n",
    "\n",
    "\n",
    "# ensure all datasets are long enough to sample sequence lengths\n",
    "assert(dataset_1[0][0].size()[1] >= seq_len)\n",
    "assert(dataset_2[0][0].size()[1] >= seq_len)\n",
    "assert(dataset_3[0][0].size()[1] >= seq_len)\n",
    "assert(dataset_4[0][0].size()[1] >= seq_len)\n",
    "assert(dataset_5[0][0].size()[1] >= seq_len)\n",
    "assert(dataset_6[0][0].size()[1] >= seq_len)\n",
    "\n",
    "print(\"individual datasets created\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# main training loop adapted from in class lab examples\n",
    "def train_model(model, dataloader, optimizer, loss_function, scheduler, num_epochs = 10, verbose = False, print_metrics=False):\n",
    "    acc_dict = {'train':[],'validate':[]}\n",
    "    loss_dict = {'train':[],'validate':[]}\n",
    "    recall_dict = {'train':[],'validate':[]}\n",
    "    specificity_dict = {'train':[],'validate':[]}\n",
    "    AUROC_dict = {'train':[],'validate':[]}\n",
    "    AP_dict = {'train':[],'validate':[]}\n",
    "    \n",
    "    best_AUROC = 0\n",
    "    phases = ['train', 'validate']\n",
    "    since = time.time()\n",
    "    for i in range(num_epochs):\n",
    "        print('Epoch: {}/{}'.format(i, num_epochs-1))\n",
    "        print('-'*10)\n",
    "        batch = 0\n",
    "        for p in phases:\n",
    "            running_correct = 0\n",
    "            running_loss = 0\n",
    "            running_total = 0\n",
    "            if p == 'train':\n",
    "                model.train()\n",
    "            else:\n",
    "                model.eval()\n",
    "            \n",
    "            all_predictions = []\n",
    "            all_labels = []\n",
    "            \n",
    "            \n",
    "            for data in dataloader[p]:\n",
    "                optimizer.zero_grad()\n",
    "                seq = data[0].to(device)\n",
    "\n",
    "                \n",
    "                \n",
    "                label = data[1].to(device)\n",
    "                y_pred = model(seq)\n",
    "                \n",
    "\n",
    "                \n",
    "                loss = loss_function(y_pred, label.long().squeeze())\n",
    "                _, preds = torch.max(y_pred, dim = 1)\n",
    "                num_seqs = seq.size()[0]\n",
    "\n",
    "                \n",
    "                pr = preds.clone().cpu().detach().numpy()\n",
    "                lb = label.clone().cpu().detach().numpy()\n",
    "                \n",
    "                all_predictions = np.concatenate([all_predictions, pr], axis=None)\n",
    "                all_labels = np.concatenate([all_labels, lb], axis=None)\n",
    "                \n",
    "                \n",
    "\n",
    "\n",
    "                ########################\n",
    "                ## PRINT BATCH METRICS#\n",
    "                #####################\n",
    "                if print_metrics:\n",
    "                    try:\n",
    "                        connection_calls = torch.sum((preds==1))\n",
    "                        correct_calls = torch.sum(preds == label)\n",
    "                        connection_call_accuracy = ((correct_calls.item()) / (connection_calls.item()))\n",
    "\n",
    "                        print(\"connections present: {}\".format(torch.sum(label.view(-1).long())))\n",
    "                        print(\"connection calls: {}\".format(connection_calls))\n",
    "                        #print(\"connection call accuracy: {}\".format(connection_call_accuracy))\n",
    "                        #print(\"\\n\")\n",
    "                \n",
    "\n",
    "                \n",
    "                        pr = preds.clone().cpu().detach().numpy()\n",
    "                        lb = label.clone().cpu().detach().numpy()  \n",
    "                        tn, fp, fn, tp = confusion_matrix(lb, pr).ravel()\n",
    "\n",
    "                        specificity = tn / (tn + fp)\n",
    "                        precision = tp / (tp + fp)\n",
    "                        recall = tp / (tp + fn)\n",
    "                        f1 = (2*tp /( 2*tp + fp + fn))\n",
    "                        #print(\"precision: {}\".format(precision))\n",
    "                        print(\"recall: {}\".format(recall))\n",
    "                        print(\"specificity: {}\".format(specificity))\n",
    "                        print(\"f1: {}\".format(f1))\n",
    "                    except:\n",
    "                        print(\"whoopsie\")\n",
    "                    print(\"loss: {}\".format(loss.item()))\n",
    "                    print(\"\\n\")\n",
    "                \n",
    "                running_correct += torch.sum(preds == label.view(-1).long()).item()\n",
    "                #print(\"running correct: {}\".format(running_correct))\n",
    "                running_loss += loss.item()*num_seqs\n",
    "                running_total += num_seqs\n",
    "                #print(\"running total: {}\".format(running_total))\n",
    "                running_acc = running_loss / running_total\n",
    "                #print(\"running_acc: {}\".format(running_acc))\n",
    "                \n",
    "                \n",
    "                if p == 'train':\n",
    "                    loss.backward()\n",
    "                    clipping_value = 0.5 #\n",
    "                    torch.nn.utils.clip_grad_norm_(model.parameters(), clipping_value)\n",
    "                    optimizer.step()\n",
    "                \n",
    "                #print(\"\\n\")\n",
    "            epoch_acc = float(running_correct/running_total)\n",
    "            epoch_loss = float(running_loss/running_total)\n",
    "            \n",
    "            tn, fp, fn, tp = confusion_matrix(all_labels, all_predictions).ravel()\n",
    "            fpr, tpr, thresholds = roc_curve(all_labels, all_predictions, pos_label=1)\n",
    "            epoch_AP = average_precision_score(all_labels, all_predictions, pos_label=1)\n",
    "            epoch_AUROC = auc(fpr, tpr)\n",
    "            \n",
    "       \n",
    "            epoch_specificity = tn / (tn + fp)\n",
    "            epoch_precision = tp / (tp + fp)\n",
    "            epoch_recall = tp / (tp + fn)\n",
    "            epoch_f1 = (2*tp /( 2*tp + fp + fn))\n",
    "            #print(\"precision: {}\".format(precision))\n",
    "            print(\"recall: {}\".format(epoch_recall))\n",
    "            print(\"specificity: {}\".format(epoch_specificity))\n",
    "            print(\"f1: {}\".format(epoch_f1))\n",
    "            print(\"AUROC: {}\".format(epoch_AUROC))\n",
    "            print(\"AP: {}\".format(epoch_AP))\n",
    "            \n",
    "            \n",
    "            if verbose or (i%10 == 0):\n",
    "                print('Phase:{}, epoch loss: {:.4f} Acc: {:.4f}'.format(p, epoch_loss, epoch_acc))\n",
    "                print('\\n')\n",
    "            \n",
    "            # add metrics to epoch dict\n",
    "            acc_dict[p].append(epoch_acc)\n",
    "            loss_dict[p].append(epoch_loss)\n",
    "            recall_dict[p].append(epoch_recall)\n",
    "            specificity_dict[p].append(epoch_specificity)\n",
    "            AUROC_dict[p].append(epoch_AUROC)\n",
    "            AP_dict[p].append(epoch_AP)\n",
    "            \n",
    "            \n",
    "            # choose to retain model based on AUROC\n",
    "            if p == 'validate':\n",
    "                if epoch_AUROC > best_AUROC:\n",
    "                    best_AUROC = epoch_AUROC\n",
    "                    best_model_wts = model.state_dict()\n",
    "            else:\n",
    "                if scheduler:\n",
    "                    scheduler.step()\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val AUROC: {:4f}'.format(best_AUROC))\n",
    "    \n",
    "    model.load_state_dict(best_model_wts)\n",
    "    \n",
    "    return model, acc_dict, loss_dict, recall_dict, specificity_dict, AUROC_dict, AP_dict\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# START TO DEFINE MODEL MODULES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# optional recurrent \"front end\" to for sequence representation transformation\n",
    "class seq2seq(nn.Module):\n",
    "    def __init__(self, hidden_size):\n",
    "        super(seq2seq, self).__init__()\n",
    "        \n",
    "        self.hidden_size = hidden_size\n",
    "        self.recurrent_layer = nn.Sequential(\n",
    "            nn.GRU(\n",
    "                input_size = 3,\n",
    "                hidden_size = self.hidden_size,\n",
    "                num_layers = 3,\n",
    "                batch_first = True,\n",
    "                dropout = 0.1,\n",
    "                bidirectional = True),\n",
    "            \n",
    "        )\n",
    "\n",
    "        self.reduce_features1 = nn.Conv2d(\n",
    "            in_channels = 24,\n",
    "            out_channels = 12,\n",
    "            kernel_size =  1)\n",
    "        \n",
    "        self.reduce_features2 = nn.Conv2d(\n",
    "            in_channels=12,\n",
    "            out_channels = 4,\n",
    "            kernel_size = 1)\n",
    "         \n",
    "        self.relu  = nn.ReLU()\n",
    "        \n",
    "    def forward(self, x, verbose=False):\n",
    "        self.verbose = verbose\n",
    "        x = x.transpose(1,2)\n",
    "        \n",
    "         \n",
    "        x, _ = self.recurrent_layer(x)\n",
    "        x = x.transpose(1,2)\n",
    "        \n",
    "        x = x.unsqueeze(2)\n",
    "        x = self.relu(x)\n",
    "                \n",
    "        x = x.squeeze()\n",
    "        \n",
    "        if self.verbose:\n",
    "            print(\"seq2seq input shape: {}\".format(x.size()))\n",
    "            print(\"out size: {}\".format(x.size()))\n",
    "        return(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# first convolutional block module, Inception v2 style with optional residual connection\n",
    "class connception_module1(nn.Module):\n",
    "    def __init__(self, residual = False):\n",
    "        super(connception_module1, self).__init__()\n",
    "        \n",
    "        self.residual = residual\n",
    "        \n",
    "        self.branch_1x = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                in_channels = 32,\n",
    "                out_channels = 8,\n",
    "                kernel_size = 1)\n",
    "        )\n",
    "        \n",
    "        self.branch_3x = nn.Sequential(            \n",
    "            nn.Conv2d(\n",
    "                in_channels = 32,\n",
    "                out_channels = 4,\n",
    "                kernel_size = 1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(\n",
    "                in_channels = 4,\n",
    "                out_channels = 8,\n",
    "                kernel_size = [3,3],\n",
    "                padding = [1,1]            \n",
    "            )\n",
    "        )\n",
    "        \n",
    "        self.branch_5x = nn.Sequential(            \n",
    "            nn.Conv2d(\n",
    "                in_channels = 32,\n",
    "                out_channels = 4,\n",
    "                kernel_size = 1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(\n",
    "                in_channels = 4,\n",
    "                out_channels = 8,\n",
    "                kernel_size = [3,3],\n",
    "                padding = [1,1]),\n",
    "            nn.Conv2d(\n",
    "                in_channels = 8,\n",
    "                out_channels = 8,\n",
    "                kernel_size = [3,3],\n",
    "                padding = [1,1])  \n",
    "        )\n",
    "        \n",
    "        self.branch_mp = nn.Sequential(\n",
    "            nn.AdaptiveMaxPool2d(\n",
    "                output_size = [3,330]),\n",
    "            nn.Conv2d(\n",
    "                in_channels = 32,\n",
    "                out_channels = 8,\n",
    "                kernel_size = 1)\n",
    "        )\n",
    "\n",
    "        self.batch_norm = nn.BatchNorm2d(32)\n",
    "\n",
    "            \n",
    "    def forward(self, x, residual=False, verbose=False):\n",
    "            self.residual = residual\n",
    "            \n",
    "            branch_1x = self.branch_1x(x)\n",
    "            if verbose:\n",
    "                print(\"connception module 2 branch 1x size: {}\".format(branch_1x.size()))\n",
    "            branch_3x = self.branch_3x(x)\n",
    "            if verbose:\n",
    "                print(\"connception module 2 branch 3x size: {}\".format(branch_3x.size()))\n",
    "            branch_5x = self.branch_5x(x)\n",
    "            if verbose:\n",
    "                print(\"connception module 2 branch 5x size: {}\".format(branch_5x.size()))\n",
    "            branch_mp = self.branch_mp(x)\n",
    "            if verbose:\n",
    "                print(\"connception module 2 branch mp size: {}\".format(branch_mp.size()))\n",
    "\n",
    "            \n",
    "            out = torch.cat(\n",
    "                (branch_1x,\n",
    "                 branch_3x,\n",
    "                 branch_5x,\n",
    "                 branch_mp),\n",
    "                1)\n",
    "            \n",
    "            if self.residual:\n",
    "                out += x\n",
    "            \n",
    "            out = self.batch_norm(out)\n",
    "            \n",
    "            \n",
    "            #print(\"out size: {}\".format(out.size()))\n",
    "            return(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# first convolutional block with residual architecture from Dunn & Koo (2017)\n",
    "class connception_block1(nn.Module):\n",
    "    def __init__(self, first_input = False, rfe = False):\n",
    "        super(connception_block1, self).__init__()\n",
    "        \n",
    "        # condition input seq of lengths BATCH x 3 X 330\n",
    "        self.rfe = rfe\n",
    "        if self.rfe:\n",
    "            self.conv1 = nn.Sequential(\n",
    "                nn.Conv2d(\n",
    "                           in_channels = 1,\n",
    "                           out_channels = 32, \n",
    "                           kernel_size = [8,5], \n",
    "                           stride = [8,1],\n",
    "                           padding = [0,2], \n",
    "                           dilation = 1, \n",
    "                           bias = True, \n",
    "                           padding_mode = 'zeros'\n",
    "                        ),           \n",
    "            )\n",
    "        else:\n",
    "            self.conv1 = nn.Sequential(\n",
    "                nn.Conv2d(\n",
    "                           in_channels = 1,\n",
    "                           out_channels = 32, \n",
    "                           kernel_size = [1,5], \n",
    "                           stride = 1,\n",
    "                           padding = [0,2], \n",
    "                           dilation = 1, \n",
    "                           bias = True, \n",
    "                           padding_mode = 'zeros'\n",
    "                        ),           \n",
    "            )\n",
    "\n",
    "        self.first_input = first_input\n",
    "        self.connception1 = connception_module1()       \n",
    "        self.connception2 = connception_module1()        \n",
    "        self.connception3 = connception_module1()\n",
    "        \n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "    def forward(self, x, verbose = False):        \n",
    "        self.verbose = verbose\n",
    "        # if first input, add dimension for convolution\n",
    "        if self.verbose:\n",
    "            print(\"input sequence size: {}\".format(x.size()))\n",
    "        \n",
    "        if self.first_input:\n",
    "            input_seq = x.unsqueeze(1)\n",
    "            x = self.conv1(input_seq)      \n",
    "        if self.verbose:\n",
    "            print(\"post 'input convolution' size: {}\".format(x.size()))\n",
    "        \n",
    "        \n",
    "        x = self.connception1(x, self.verbose)\n",
    "        residual = x\n",
    "        \n",
    "        x = self.relu(self.connception2(x, residual=True))\n",
    "        x = self.relu(self.connception3(x, residual=True))\n",
    "        \n",
    "        x+=residual\n",
    "        \n",
    "        if self.verbose:\n",
    "            print(\"connception block 1 output size: {}\".format(x.size()))\n",
    "        \n",
    "        return(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# second convolutional block module, Inception v2 style with optional residual connection\n",
    "\n",
    "class connception_module2(nn.Module):\n",
    "    def __init__(self, residual = False):\n",
    "        super(connception_module2, self).__init__()\n",
    "        \n",
    "        self.residual = residual\n",
    "        \n",
    "        self.branch_1x = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                in_channels = 64,\n",
    "                out_channels = 16,\n",
    "                kernel_size = 1)\n",
    "        )\n",
    "        \n",
    "        self.branch_3x = nn.Sequential(            \n",
    "            nn.Conv2d(\n",
    "                in_channels = 64,\n",
    "                out_channels = 8,\n",
    "                kernel_size = [2,1],\n",
    "                padding = [1,0]),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(\n",
    "                in_channels = 8,\n",
    "                out_channels = 16,\n",
    "                kernel_size = [2,3],\n",
    "                padding = [0,1]            \n",
    "            )\n",
    "        )\n",
    "        \n",
    "        self.branch_5x = nn.Sequential(            \n",
    "            nn.Conv2d(\n",
    "                in_channels = 64,\n",
    "                out_channels = 8,\n",
    "                kernel_size = [2,1],\n",
    "                padding = [1,0]),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(\n",
    "                in_channels = 8,\n",
    "                out_channels = 16,\n",
    "                kernel_size = [3,3],\n",
    "                padding = [1,1]),\n",
    "            nn.Conv2d(\n",
    "                in_channels = 16,\n",
    "                out_channels = 16,\n",
    "                kernel_size = [2,3],\n",
    "                padding = [0,1])  \n",
    "        )\n",
    "        \n",
    "        self.branch_mp = nn.Sequential(\n",
    "            nn.AdaptiveMaxPool2d(\n",
    "                output_size = [2,110]),\n",
    "            nn.Conv2d(\n",
    "                in_channels = 64,\n",
    "                out_channels = 16,\n",
    "                kernel_size = 1)\n",
    "        )\n",
    "\n",
    "        self.batch_norm = nn.BatchNorm2d(64)\n",
    "        self.relu = nn.ReLU()\n",
    "            \n",
    "    def forward(self, x, residual=False, verbose=False):\n",
    "\n",
    "            self.residual = residual\n",
    "            self.verbose = verbose\n",
    "            \n",
    "            branch_1x = self.branch_1x(x)\n",
    "            branch_3x = self.branch_3x(x)                \n",
    "            branch_5x = self.branch_5x(x)                \n",
    "            branch_mp = self.branch_mp(x)\n",
    "\n",
    "            if verbose:\n",
    "                print(\"connception module 2 branch 1x size: {}\".format(branch_1x.size()))\n",
    "                print(\"connception module 2 branch 3x size: {}\".format(branch_3x.size()))\n",
    "                print(\"connception module 2 branch 5x size: {}\".format(branch_5x.size()))\n",
    "                print(\"connception module 2 branch mp size: {}\".format(branch_mp.size()))\n",
    "            \n",
    "            out = torch.cat(\n",
    "                (\n",
    "                branch_1x,\n",
    "                branch_3x,\n",
    "                branch_5x,\n",
    "                branch_mp),\n",
    "                1)\n",
    "            \n",
    "            \n",
    "            if self.residual:\n",
    "                out += x\n",
    "            \n",
    "            out = self.batch_norm(out)\n",
    "            \n",
    "            \n",
    "            return(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# second convolutional block with residual architecture from Dunn & Koo (2017)\n",
    "\n",
    "class connception_block2(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(connception_block2, self).__init__()\n",
    "        \n",
    "        # condition input from connception block 1\n",
    "        # size B x 128 x 3 x seqlen --> B x 256 x 2 x seqlen \n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                in_channels = 32,\n",
    "                out_channels = 64, \n",
    "                kernel_size = [2,3],\n",
    "                padding = [0,1],\n",
    "                stride = [1,3], \n",
    "                dilation = 1, \n",
    "                bias = True)\n",
    "        )\n",
    " \n",
    "        self.connception1 = connception_module2()       \n",
    "        self.connception2 = connception_module2()        \n",
    "        self.connception3 = connception_module2()\n",
    "        \n",
    "        self.connception4 = connception_module2()       \n",
    "        self.connception5 = connception_module2()        \n",
    "        self.connception6 = connception_module2()\n",
    "        \n",
    "        self.relu = nn.ReLU()\n",
    "        self.max_pool_out = nn.AdaptiveMaxPool2d(\n",
    "            output_size = [2,110])\n",
    "        \n",
    "        \n",
    "    def forward(self, x, verbose=False):   \n",
    "        \n",
    "        self.verbose = verbose\n",
    "        \n",
    "        # convolution to match dimensions\n",
    "        x = self.conv1(x)\n",
    "        if self.verbose:\n",
    "            print(\"post connception block 2 input conv size: {}\".format(x.size()))\n",
    "        \n",
    "        x = self.connception1(x)\n",
    "        x = self.relu(x)\n",
    "        residual = x\n",
    "        \n",
    "        x = self.connception2(x, verbose = self.verbose, residual=True)\n",
    "        x = self.relu(x)\n",
    "        x = self.connception3(x, verbose = self.verbose, residual=True)\n",
    "        x = self.relu(x)\n",
    "        residual = x\n",
    "        \n",
    "        \n",
    "        if self.verbose:\n",
    "            print(\"connception block 2 output size: {}\".format(x.size()))\n",
    "        \n",
    "        return(x)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# final convolutional module, collapse to 1d sequence using Inception v2 style filter arrangement\n",
    "class connception_module3(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(connception_module3, self).__init__()\n",
    "        \n",
    "        self.branch_1x = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                in_channels = 64,\n",
    "                out_channels = 16,\n",
    "                kernel_size = [2,1])\n",
    "        )\n",
    "        \n",
    "        self.branch_3x = nn.Sequential(            \n",
    "            nn.Conv2d(\n",
    "                in_channels = 64,\n",
    "                out_channels = 16,\n",
    "                kernel_size = [2,1],\n",
    "                padding = [0,0]),\n",
    "            nn.Conv1d(\n",
    "                in_channels = 16,\n",
    "                out_channels = 16,\n",
    "                kernel_size = [1,3],\n",
    "                padding = [0,1]            \n",
    "            )\n",
    "        )\n",
    "        \n",
    "        self.branch_5x = nn.Sequential(            \n",
    "            nn.Conv2d(\n",
    "                in_channels = 64,\n",
    "                out_channels = 16,\n",
    "                kernel_size = [2,1],\n",
    "                padding = [0,0]),\n",
    "            nn.Conv2d(\n",
    "                in_channels = 16,\n",
    "                out_channels = 16,\n",
    "                kernel_size = [1,3],\n",
    "                padding = [0,1]),\n",
    "            nn.Conv2d(\n",
    "                in_channels = 16,\n",
    "                out_channels = 16,\n",
    "                kernel_size = [1,3],\n",
    "                padding = [0,1])  \n",
    "        )\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        self.feature_reduce = nn.Conv2d(\n",
    "            in_channels = 48,\n",
    "            out_channels = 16,\n",
    "            kernel_size = 1)\n",
    "\n",
    "        self.relu = nn.ReLU()\n",
    "        self.max_pool = nn.AdaptiveMaxPool1d(output_size = 64)\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "    def forward(self, x, verbose=False):\n",
    "        self.verbose = verbose\n",
    "        \n",
    "        branch_1x = self.branch_1x(x)                \n",
    "        branch_3x = self.branch_3x(x)                \n",
    "        branch_5x = self.branch_5x(x)                \n",
    "\n",
    "        if verbose:\n",
    "            print(\"connception module 3 branch 1x size: {}\".format(branch_1x.size()))\n",
    "            print(\"connception module 3 branch 3x size: {}\".format(branch_3x.size()))\n",
    "            print(\"connception module 3 branch 5x size: {}\".format(branch_5x.size()))\n",
    "#             print(\"connception module 2 branch mp size: {}\".format(branch_mp.size()))\n",
    "\n",
    "        x = torch.cat(\n",
    "            (\n",
    "            branch_1x,\n",
    "            branch_3x,\n",
    "            branch_5x),\n",
    "            1)\n",
    "        \n",
    "        \n",
    "        x = self.feature_reduce(x)        \n",
    "        x = self.relu(x)\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        x = x.squeeze(2)\n",
    "        x = self.max_pool(x)\n",
    "            \n",
    "        if self.verbose:\n",
    "            print(\"connception block 3 output size: {}\".format(x.size()))    \n",
    "            \n",
    "            \n",
    "        return(x)\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# recurrent portion of classifier output, gated recurrent unit \n",
    "class connception_recurrent_out(nn.Module):\n",
    "    def __init__(self, hidden_size):\n",
    "        super(connception_recurrent_out, self).__init__()\n",
    "    \n",
    "        self.hidden_size = hidden_size\n",
    "        self.gru = nn.GRU(\n",
    "            input_size = 16,\n",
    "            hidden_size = self.hidden_size,\n",
    "            \n",
    "            num_layers = 2,\n",
    "            bias = True,\n",
    "            batch_first = True,\n",
    "            dropout = 0,\n",
    "            bidirectional = True\n",
    "        )\n",
    "        \n",
    "    def forward(self, x, verbose=False):\n",
    "        self.verbose = verbose\n",
    "        #condition shape for GRU input\n",
    "        x = x.squeeze(2).transpose(1,2)\n",
    "        if self.verbose:\n",
    "            print('post transpose shape: {}'.format(x.size()))\n",
    " \n",
    "        x, h_n = self.gru(x)\n",
    "        h_n = h_n.transpose(0,1).flatten(start_dim=1, end_dim=-1)\n",
    "        \n",
    "        out = h_n\n",
    "        \n",
    "        if self.verbose:\n",
    "            print('recurrent out size: {}'.format(out.size()))\n",
    "        \n",
    "        \n",
    "        return(out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# classifier output fully connected module, takes hidden state from GRU and produces two output numbers\n",
    "class connception_fc(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(connception_fc, self).__init__()\n",
    "        \n",
    "        self.fc1 = nn.Linear(64, 16)\n",
    "        self.fc2 = nn.Linear(16, 16)\n",
    "        self.fc3 = nn.Linear(16, 2)\n",
    "       \n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "    def forward(self, x, verbose=False):\n",
    "        self.verbose = verbose\n",
    "        \n",
    "        x = x.view(x.size(0), -1)\n",
    "        if self.verbose:\n",
    "            print('post transpose shape: {}'.format(x.size()))\n",
    "\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "             \n",
    "        \n",
    "        return(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# define model with Recurrent Front End (RFE version)\n",
    "class tmodel_rfe(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(tmodel_rfe, self).__init__()\n",
    "        \n",
    "        self.s2s_hidden_size = 12\n",
    "        self.recurrent_out_size = 16\n",
    "        \n",
    "        self.seq2seq = seq2seq(hidden_size = self.s2s_hidden_size)\n",
    "        \n",
    "        self.conv_block1 = connception_block1(first_input=True, rfe=True)\n",
    "        self.conv_block2 = connception_block2()\n",
    "        self.conv_block3 = connception_module3()\n",
    "\n",
    "        self.connception_recurrent_out = connception_recurrent_out(self.recurrent_out_size)    \n",
    "        self.connception_fc = connception_fc()\n",
    "        \n",
    "        \n",
    "        \n",
    "        self.batch_norm = nn.BatchNorm1d(16)\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "        \n",
    "    def forward(self, x, verbose=False):\n",
    "        self.verbose = verbose\n",
    "        \n",
    "        if self.verbose:\n",
    "            print(\"input size: {}\".format(x.size()))\n",
    "        \n",
    "        x = self.seq2seq(x, verbose=self.verbose)\n",
    "        \n",
    "        x = self.conv_block1(x, verbose=self.verbose)\n",
    "        x = self.relu(x)\n",
    "        \n",
    "        x = self.conv_block2(x, verbose=self.verbose)\n",
    "        x = self.relu(x)\n",
    "        \n",
    "        x = self.conv_block3(x, verbose=self.verbose) \n",
    "        x = self.relu(x)\n",
    "        x = self.batch_norm(x)\n",
    "        \n",
    "        x = self.connception_recurrent_out(x, verbose = self.verbose)\n",
    "    \n",
    "    \n",
    "        x = self.connception_fc(x, verbose=self.verbose)\n",
    "        \n",
    "        \n",
    "        return(x)\n",
    "           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# define model with no rfe\n",
    "class tmodel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(tmodel, self).__init__()\n",
    "        \n",
    "        self.s2s_hidden_size = 12\n",
    "        self.recurrent_out_size = 16\n",
    "        \n",
    "        self.seq2seq = seq2seq(hidden_size = self.s2s_hidden_size)\n",
    "        \n",
    "        self.conv_block1 = connception_block1(first_input=True, rfe=False)\n",
    "        self.conv_block2 = connception_block2()\n",
    "        self.conv_block3 = connception_module3()\n",
    "\n",
    "        self.connception_recurrent_out = connception_recurrent_out(self.recurrent_out_size)    \n",
    "        self.connception_fc = connception_fc()\n",
    "        \n",
    "        \n",
    "        \n",
    "        self.batch_norm = nn.BatchNorm1d(16)\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "        \n",
    "    def forward(self, x, verbose=False):\n",
    "        self.verbose = verbose\n",
    "        \n",
    "        if self.verbose:\n",
    "            print(\"input size: {}\".format(x.size()))\n",
    "        \n",
    "        #x = self.seq2seq(x, verbose=self.verbose)\n",
    "        \n",
    "        x = self.conv_block1(x, verbose=self.verbose)\n",
    "        x = self.relu(x)\n",
    "        \n",
    "        x = self.conv_block2(x, verbose=self.verbose)\n",
    "        x = self.relu(x)\n",
    "        \n",
    "        x = self.conv_block3(x, verbose=self.verbose) \n",
    "        x = self.relu(x)\n",
    "        x = self.batch_norm(x)\n",
    "        \n",
    "        x = self.connception_recurrent_out(x, verbose = self.verbose)\n",
    "    \n",
    "    \n",
    "        x = self.connception_fc(x, verbose=self.verbose)\n",
    "        \n",
    "        \n",
    "        return(x)\n",
    "           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# clear CUDA memory\n",
    "try:\n",
    "    del model\n",
    "    torch.cuda.empty_cache()\n",
    "except:\n",
    "    pass\n",
    "\n",
    "\n",
    "# set training parameters and train\n",
    "\n",
    "batch_size = 100\n",
    "\n",
    "\n",
    "dataloader = {x: DataLoader(transformed_dataset[x], \n",
    "                            batch_size=batch_size,\n",
    "                            shuffle=True, \n",
    "                            num_workers=0) for x in ['train', 'validate']}\n",
    "data_sizes = {x: len(transformed_dataset[x]) for x in ['train', 'validate']}\n",
    "\n",
    "\n",
    "model = tmodel()\n",
    "\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "loss = nn.CrossEntropyLoss(weight=torch.Tensor([0.15, 0.85]).cuda())\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr = 1e-4)\n",
    "lambda_func = lambda epoch: 0.9 ** epoch\n",
    "scheduler = optim.lr_scheduler.LambdaLR(optimizer, lr_lambda=lambda_func)\n",
    "model, acc_dict, loss_dict, recall_dict, specificity_dict, AUROC_dict, AP_dict = train_model(model, dataloader, optimizer, loss, scheduler=scheduler, num_epochs=50, print_metrics=False, verbose = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "## PLOT METRICS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# model accuracy\n",
    "\n",
    "plt.plot(acc_dict['train'], label='train')\n",
    "plt.plot(acc_dict['validate'], label='validation')\n",
    "plt.title(\"Model Accuracy over Epochs\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# model loss\n",
    "\n",
    "plt.plot(loss_dict['train'], label='train')\n",
    "plt.plot(loss_dict['validate'], label= 'validation')\n",
    "plt.title(\"Training / Validation Loss over Epochs\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Weighted Cross Entropy Loss \\n [0.15, 0.85]\")\n",
    "plt.legend()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#model recall\n",
    "\n",
    "plt.plot(recall_dict['train'], label='train')\n",
    "plt.plot(recall_dict['validate'])\n",
    "plt.title(\"Model Recall over Epochs\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Recall\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#model specificity\n",
    "\n",
    "plt.plot(specificity_dict['train'], label='train')\n",
    "plt.plot(specificity_dict['validate'], label= 'validation')\n",
    "plt.title(\"Model Specificity over Epochs\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Specificity\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#model AUROC\n",
    "\n",
    "plt.plot(AUROC_dict['train'], label='train')\n",
    "plt.plot(AUROC_dict['validate'], label= 'validation')\n",
    "plt.title(\"AUROC over Epochs\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"AUROC\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#model AP\n",
    "\n",
    "plt.plot(AP_dict['train'], label='train')\n",
    "plt.plot(AP_dict['validate'], label= 'validation')\n",
    "plt.title(\"AP over Epochs\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"AP\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "test_loader = DataLoader(dataset_6, \n",
    "                            batch_size=100,\n",
    "                            shuffle=True, \n",
    "                            num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "## OPTIONAL CELL TO LOAD PREVIOUSLY SAVED MODELS FOR TESTINGG\n",
    "# model = tmodel().to(device)\n",
    "# state_dict = torch.load(\"/scratch/dmc421/dlproject/model_state\")\n",
    "# model.load_state_dict(state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# main testing\n",
    "# run 5 times and record results\n",
    "def test_model(model, dataloader, verbose = True, print_metrics=False):\n",
    "    acc_dict = {'test':[]}\n",
    "    loss_dict = {'test':[]}\n",
    "    recall_dict = {'test':[]}\n",
    "    specificity_dict = {'test':[]}\n",
    "    AUROC_dict = {'test':[]}\n",
    "    AP_dict = {'test':[]}\n",
    "    \n",
    "    best_AP = 0\n",
    "    phases = ['test']\n",
    "    since = time.time()\n",
    "    for i in range(1):\n",
    "        batch = 0\n",
    "        for p in phases:\n",
    "            running_correct = 0\n",
    "            running_loss = 0\n",
    "            running_total = 0\n",
    "            model.eval()\n",
    "            \n",
    "            all_predictions = []\n",
    "            all_labels = []\n",
    "            \n",
    "            \n",
    "            for data in dataloader:\n",
    "\n",
    "                seq = data[0].to(device)\n",
    "\n",
    "                \n",
    "                \n",
    "                label = data[1].to(device)\n",
    "                y_pred = model(seq)\n",
    "                \n",
    "\n",
    "                \n",
    "#                 loss = loss_function(y_pred, label.long().squeeze())\n",
    "                _, preds = torch.max(y_pred, dim = 1)\n",
    "                num_seqs = seq.size()[0]\n",
    "\n",
    "                \n",
    "                pr = preds.clone().cpu().detach().numpy()\n",
    "                lb = label.clone().cpu().detach().numpy()\n",
    "                \n",
    "                all_predictions = np.concatenate([all_predictions, pr], axis=None)\n",
    "                all_labels = np.concatenate([all_labels, lb], axis=None)\n",
    "                \n",
    "                \n",
    "\n",
    "\n",
    "                ########################\n",
    "                ## PRINT BATCH METRICS#\n",
    "                #####################\n",
    "                if print_metrics:\n",
    "                    try:\n",
    "                        connection_calls = torch.sum((preds==1))\n",
    "                        correct_calls = torch.sum(preds == label)\n",
    "                        connection_call_accuracy = ((correct_calls.item()) / (connection_calls.item()))\n",
    "\n",
    "                        print(\"connections present: {}\".format(torch.sum(label.view(-1).long())))\n",
    "                        print(\"connection calls: {}\".format(connection_calls))\n",
    "                        #print(\"connection call accuracy: {}\".format(connection_call_accuracy))\n",
    "                        #print(\"\\n\")\n",
    "                \n",
    "\n",
    "                \n",
    "                        pr = preds.clone().cpu().detach().numpy()\n",
    "                        lb = label.clone().cpu().detach().numpy()  \n",
    "                        tn, fp, fn, tp = confusion_matrix(lb, pr).ravel()\n",
    "\n",
    "                        specificity = tn / (tn + fp)\n",
    "                        precision = tp / (tp + fp)\n",
    "                        recall = tp / (tp + fn)\n",
    "                        f1 = (2*tp /( 2*tp + fp + fn))\n",
    "                        #print(\"precision: {}\".format(precision))\n",
    "                        print(\"recall: {}\".format(recall))\n",
    "                        print(\"specificity: {}\".format(specificity))\n",
    "                        print(\"f1: {}\".format(f1))\n",
    "                    except:\n",
    "                        print(\"whoopsie\")\n",
    "                    print(\"loss: {}\".format(loss.item()))\n",
    "                    print(\"\\n\")\n",
    "                \n",
    "                running_correct += torch.sum(preds == label.view(-1).long()).item()\n",
    "                #print(\"running correct: {}\".format(running_correct))\n",
    "\n",
    "                running_total += num_seqs\n",
    "                #print(\"running total: {}\".format(running_total))\n",
    "                running_acc = running_loss / running_total\n",
    "                #print(\"running_acc: {}\".format(running_acc))\n",
    "                \n",
    "                \n",
    "                #print(\"\\n\")\n",
    "            epoch_acc = float(running_correct/running_total)\n",
    "\n",
    "            \n",
    "            tn, fp, fn, tp = confusion_matrix(all_labels, all_predictions).ravel()\n",
    "            fpr, tpr, thresholds = roc_curve(all_labels, all_predictions, pos_label=1)\n",
    "            epoch_AP = average_precision_score(all_labels, all_predictions, pos_label=1)\n",
    "            epoch_AUROC = auc(fpr, tpr)\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            epoch_specificity = tn / (tn + fp)\n",
    "            epoch_precision = tp / (tp + fp)\n",
    "            epoch_recall = tp / (tp + fn)\n",
    "            epoch_f1 = (2*tp /( 2*tp + fp + fn))\n",
    "            #print(\"precision: {}\".format(precision))\n",
    "            print(\"recall: {}\".format(epoch_recall))\n",
    "            print(\"specificity: {}\".format(epoch_specificity))\n",
    "            print(\"f1: {}\".format(epoch_f1))\n",
    "            print(\"AUROC: {}\".format(epoch_AUROC))\n",
    "            print(\"AP: {}\".format(epoch_AP))\n",
    "\n",
    "    \n",
    " \n",
    "\n",
    "test_model(model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "## SAVE MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# torch.save(model.state_dict(), \"/scratch/dmc421/dlproject/model_state.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# torch.save(model, \"/scratch/dmc421/dlproject/model.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# list model parameters\n",
    "model.parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (dlproject",
   "language": "python",
   "name": "dlproject"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
